I have the spirit ever living rightthere like the reason people would haveis kind of emotion starring one goodthing that it has is if you're eversquared then you take a derivative youget two of the elements like x squaredis two of X you get well you expect inthe example so then you two getscanceled and somehow you get somehappiness okay listen you know whatthere are other ways of saying thingslike for example a half sometimes thumbsup for you know in all sorts of ways inphysics for example how can we scale isyour kinetic energy but in general asfar as learning is concerned you couldhave just minimize this it doesn't makeany difference at all but people justthink in terms of you know me Twitter ishalf of the square desk now notice thatI'm only looking at the ft minus thevalue that the currently that niggas aresaying - the value each should have fromthe point of view of actual capitaldifference learning the actual valuethat should be the end would be whatthis alpha times reward plus beta timesthe value of the next state rememberthat's about it okay and you want to notcheat towards that so that's how you getthat other match value but for nowassume that that value is not this valueis known and you're just trying tochange the thickness so the question ishow much are you supposed to change theThetasthe whole discussion we have done is youcan change the data in the directionthat is opposite to the gradient if youcan compute theJada's okay each Delta now is a variablebecause you're trying to set there andthere are continuous variables securedto essentially try to set theta I if wetake I minus alpha times the partialderivative of the error term withrespect to theta I okay so now a littlebit up for differentiation now in factit turns out that this is the valuefunction right and the error is in termsof the value functions it's the squareof the value function minus the correctvalue okay but then what you're tryingto do is differentiate with us to betheta the device inside of this that'swhen you use the chain rule right sowhat do you do you say the derivative ofEgypt does protecta I is the derivativeof V J with respect to the V theta isimagine we can buy itself is a variableand then derivative of V theta withrespect to theta you could have anynumber of these shapes in general buthere is just have to be clever Chinesechain demonstration okay yes so thequestion then is what happens here so ifyou look at I'm like trying to computethis so this is now four times dou mu Gby dou theta i where this part the EJfield remember is half of V theta minusV s JH squared so if you justdifferentiate this part as if V theta isitself a variable right then what youget if it's two times V theta minus Vokay so that's basically what I havehere two times V theta minus V and thenthe half that was sitting there getscancelled with the two so you just have- me that you are mediating perspectivethe derivative of V J with respect tomediator and now I know differentiate wedo that with respect to the waitingcells now of course this depends on howvalue is represented in terms of thefeatures for us it's just a linearfunction right so remember that my valuefunction is this differentiate thisfunction this linear function withrespect to theta I so let'sdifferentiate with respect to theta tothe guy in the red shirt in the backhello what's the answer you come to theclass not to just find the codeunderstand yeahokay please pay attention otherwise youknow there is no difference betweenbeing here and sleeping and sitting athome and sleepingso what's the answer for somebody who'sactually paying attention that's do itshort answer right because if theta 2 isthe variable then theta 1 doesn't changewith respect to theta 2 so that becomes0 and 1 doesn't change that becomes 0 0times anything is 0 this is theta 2 ischanging with respect to theta 2exactly so be theta by theta is 1 okayso when you get they have to heareverything else is 0 so what I got wasthat the differential is just thefeature value for the I thought that theJ dimension okay so I did all mycalculation and then essentially I got atip I should be shifted towards alpha xvs J minus VDas J times F I see Jennifer for thatstingwe cannot essentially differentiatingthis device right questions anybody thisis just calc was coming back to bite youyes I didn't say anything about comicsright now this is my action I was justtelling earlier that if you happen ifyou are ever function unbeknownst to youme happens to be a convex functionalthen when you reach the minimum thatwould be the only minimum in the worldand so you would have gotten a globalminimum but that's a different pointfrom here you're not just going throughthe machinations so I will change thedata every time a little bit in aproportional to its gradient times alphawhich is the learning rate now noticethat this change is done for each of theThetas so the best way to think aboutthis is you have a big vector theta 0 totheta K the entire vector is beingpushed in the current direction bytaking the gradient vector times alphaso you get a new weight back and youkeep doing thisin essence that's important when youstop and you go for that basically oneof the good teachers has to come to thepart of the error function that actuallyis the minimum what will happen to thegradient if we got zero so the way itwill stop changing once you get to themiddle and that point say that makes arenot changing I stop in fact most peopledon't do that they just keep going for awhile and then stop and then say likeall of us a master ehokay so this by the way is essentiallythis essentially is your yeah this isessentially you are they need descentare based value function approximationand I did it with respect to linearerror okay so if you think in terms ofhow this gets plugged in this is yourtemporal difference algorithm at somepoint of time you have to update that wevalue previously now you update thetheta values you stopped updating thevalue of the self you update the thetavalues then you update to theta valuesyou don't change just that cell valueyou say everybody else's value doanything just like when I changeupdating them relative weights forassignments to get somebody's great fallto walk below threshold everybody'sgetting changed because that a teacherbecause in some sense is generalizedacross all the states with the similarfeatures so in particular what we aredoing essentially is this vs the actualvalue that you are trying to push thevisitor to words in terms of is given byyour temporal difference funnyyou see what I'm saying okay so that isvs is our first plus beta times V thetahalf s - beta x + beta x value of theneighborhood from s - now it turns outthat the value of your neighbor is alsoin terms of this formula so on some whatdo you technical point that what we dois actually you are changing the t passby using thevalues okay so if you read more seriousreinforcement learning textbooks theypoint out that what we are doing here isnot exactly linear descent it's calledsemi immediately same but as far as thisclass is concerned we just found it youready decent and that'll be fine okay sonow the next thing is I did that fortemporal difference could I have donethis for q-learning yes I you Larrydo the only thing is essentially thereal value for the q-learningcomes from the max part minus whateveris the true value currently from the S&Hattacks being minimized that every isbeing minimized and in general if you gothrough the ever account the gradientcalculation you notice that the gradientcalculation didn't really depend uponthe form of vs chip it's just me of sj-this so it stopped this being a temporaldifference based value it could beq-learning based man you see what I'msaying in general oh how the gradientdifference updates would be proportionalto the difference between the real andwhat you want it to be okay okayso did people get this back inessentially this thing is sitting herebecause this is the value that you wantit to be this is the value it currentlyis and in trying to push it in the rightdirection so that the Thetas will changecorrectly you are essentially changingThetas not the values to the origin oftheta values times alpha times thisexpression it just happens to be thegradient it just happens to be thegradient under two assumptionsassumption one is that you have a linearweighted function our features you aredefining valueas WI times fi the second assumption isthat the MLM is being defined as asquare of the difference those are thetwo things that you used in the in thederivation right so if this is the everthis was clear because of because we -we - squid we - we had square and sothat became 2 times V - we had had thiswe defined in a different formula andthere is different different formulawhich you will be seeing in a minutein fact it suddenly defined ever to bewith - we had power for you could dothat okay and then when you areminimizing that then of course this partwill now have a 3 the 3 times B - we wehad power 3 this is that and similarlythis part became just for you justifyfor you because the way you can find thefeatures into value is a linearcombination of features do you see whatI'm saying ok if you did something elsethat you have differentiate thatfunction now here is the realistic thingif I am actually if I actually in stopdoing this this if I consider not onlythese but I also considered plus theta 1to power F 1 squared plus theta 1 totheta 2 to power F 2 square etcetera iswhat I'm sayingI'm not considering not just the featurevalues for the squares of the featurevalues in defining the value functionright the question is if you take itdifferential on this we need to have thesame nice property that we had beforehow many people think it won't have thesame nice property as before how manythink it will have the same niceproperty as beforewhat are you differentiating with whatdata it has quit theta it has vanilla nothis is by the way I'm sorry if you didhear me say it it looks like this iscreated what I was just saying okaylet's really let me call it theta 1 2herethis is great yeah what's a bad exampleokay so so theta want to have one squaretheta to do after square etc now thequestion is now I'm essentially taking alinear sum not just of the features butlinear some of the features square ofthe features cubes of the features etcetcetera change the differential no itused to be a spirit maybe have twosquare wherever it used to be if you seewhat I'm sayingthis is actually a game that we willplay later on this is essentially calleda kernel trick you can take the valuesof the features and start squaring themand you start getting more interestingways of differentiating do aclassification with no extra cost interms of doing the actualdifferentiation how are they starteddoing keep us clear then thedifferential will change you get thisokay I'm sorry for the Tong example bodywell I was I was trying to say theta 1/2and you know that's not you probablyinherit as we just a theta 1 square likeokay so they keep that in mind thatthere is a large number any linearfunction it will linear functionalfeatures even if you're taking squaresor cubes of the features will still bein a function but in general the reasonwhen you do this by the way here is aninteresting thing if you started withfour features you started with fourfeatures okay it was a four dimensionaloptimization problem now if I startedhaving it as we're here R square thetasquarenow it's become 16 features because youhave to also consider theta want it andsaid not F 1 F 2 F 1 square F 2 squareit's a try of 1 X 2 F 1 F 3 etc this isessentially increasing thedimensionality of the data in terms offeatures in general machine learningpeople always talk about reducing thatdimensional kept the data to make lifesimpler but if you increase thedimensionality you can make life simplerin a different rate you can essentiallywind up using linear you know featurefunctions which wind up having very niceproperties such as for exampleperceptrons can differentiate pluses andminuses yes this happens to be that I'mnot I'm just taking this one so for anyspecific error function I start with ithas its own properties and it turns outthat you know for a single case so letme just get to that it's paraffins whatwe did till now essentially gets us tookay two things you can think of this iswhat you've been dying to see it lookslike that if you feel like thinking ofwhatever we just did what we did is fora linear regression you say linearregression in bold letters on yourresume and wait for people to call youthey don't call me for interviews andyou say I needone Europe one threshold function thiscase if I got is been awesome andremember we saw the nature paper whichdid exactly thatbasically they did Dean's ten thirtythousand parameter function and somebodyelse said you could have done it withthe one you wrong man and that one youare looks like that okay yes thedefinition is the number of layers so inthis particular case so you can think ofthis as a perceptronin fact it is a thing where you're atintroducing the features here F 1 thisis f 0 F 1 F 2 F King introducing thevariables the weights here theta 0 theta1 theta K the semantics are that when Ido this then I do theta I fi andnormally I also I have the semanticsthat then I can apply a function G tothis for now issue G's identity functionsu G is analytic function this is asingle perceptron when you are feedingback feature values here and it ispredicting the value of site and you aretraining these leaders your trainingthese weeks such that the values becomecloser to the correct values this islinear regression okay now soand of course when you sometimes theysay that these are bootlegging you're onokay and then you can start talkingabout neural networks but let's go forthat one more if you actually startkidding about value function inreinforcement learning that's a realmatter if on the other hand you areusing their learning techniques topredict the policy what action should Idoat every state imagine this is adiscrete action space M degree which isthe ones that we have seen remember theoptimum left right then you will then berequired to predict the correct actionwhich is a categorical attribute whichis a categorical value this left this upthis down this left is right are notsouth east west those are the onereactions there is no point three timesmath plus 0.7 times South kind of anight they just these are the fouraction that you have okay if you'relearning day then you are going from adomain which you know you taking afeature vector after stage and you aretrying to say what should it be in termsof the four actions which actually it'sa slightly different problem fromregression problem it's calledclassification problem because theoutcome now is a discrete set ofcategorical values you see what I'msayingrecreational classification are veryclosely intertwined the difference is inthe case of classification you areputting out discrete values to bespherical values in the case ofregression you're putting our continuoussetup okay now it turns out that if Ialready told you that if I don't have ifI have G equal to hydratedthen this is linear regression I canstart having G to be any arbitraryfunctions and typically the kind offunctions we will look at what are thegating functions short functions okaythe simpler special functions are thestep functions which basically say ifthis value that is coming out here isequal to or greater than some numberthen it is plus one otherwise it's zerostep functions are bad misterfrancis aregreat I understand getting behaviorthey're bad because what is our hammerwhat is the hammer greatly decenteverything has to be learned withgradient descent that means you put thedifferentiation and yeah I want try todifferentiate a step function you cannotdifferentiate a step function because itit's discontinuous it's the same reasonyou don't use the absolute value in thecase of solute where you is actuallycontinuous but it's not differentiablebecause the slopes are different hereit's not even continuous the value justjumps from one place to other in thesame at the same value so in fact is noteven a function with a zero it's bothplus one and minus one okayit's the same okay so then if you don'tdo this then exceptions notice that if Istart asking its assured you can almostsee how linear regression with it andshorting a gating function can startwith a linear classifier yeah I'vealways had value to say yes other thanyou say no a second categorycollectively okay the obvious source wetalked about are these gates the stepfunctions are not good but it turns outthat you can have continuous functionswhich look like step functions but aredifferentiable one of the most usefulones that everybody talks about is 1 by1 plus E power minus X let's call thelogistic function a sigmoid function andthe sigmoid function is clearly if youthink in terms of how it will look atthe function rightif X equal to minus infinity this willbe 1 by 1 plus E power minus x minusinfinity which is 1 by 1 who are hepower infinity which is 1 by H in whichbig number which is 0 so on this sidewill be 0 and the plus infinity signwill be 1 because X will be infinity andminus E power minus infinity will be 0so 1 by 1 will be 1 at x equal to 0 whathappens to this function and X equal to0 it will be 0.5 again at X equal to 0it will be 1 by 1 plus E power 0 so 1 by1 plus 2 plus 1 this is 1 by 2 which is0.5 so this function will be sort ofgoing from minus infinity to plusinfinity while plus infinity side willbe plus 1 minus 3 design is 0 it will becrossing here and insidethat the classes would be mine so forall practical purposes it's the kind offunction that we are dreaming about it'sthe step function which looks like astep function and here it isdifferentiable and start that more it'sdifferential has a beautiful property ifyou think of G of X equal to 1 by 1 plusE power minus X then G dash of X will beshown as G of x times 1 minus G of X infact the little review that I sent youabout multivariable calculus had this asone of the examples ok now see asthey're going you can see how what isdoable with math and what you want to door getting intertwinedmaybe what you want to do is functionbut what can be differentiated Lisaquite so go ahead ok now interestinglyif I put G equal to Sigma that is 1 by 1plus E power minus X and do the sameperceptron I can't like this close toone of the greatest ideas in machinelearningit's called logistic regression it'scalled logistic regression it is thename is made to make you go crazybecause you think liberation believes isactually computing a continuous valuebut logistic regression is actually usedfor classification but the way you thinkof output of artistic regression is asthe probability so which is actually acontinuous quantity so we came fromlinear regression with one switch by byjust changing the Chi we started nowhappy you knowartistic vision I said almost but otherdifference is you are doing please infact if it really is let me show yourightif you are doing the perceptron withlogistic regression function 1 by 1 plusE power minus X as the thresholdingfunction you can do you are different ifyou can do your weight update rule letme first walk you through this and thentell you this is our most logisticregression but with a difference okay solet's go through this weight update rulehere essentially unlike the last timearound I participate so I have like itbut sacrum like this I have a wholebunch of feature values and I want tosort of say yes or no outside that's itthere will be two actions action oraction do is what I'm trying to learnand it's this is now supervised learningthat means father some number oftraining examples you know what theanswer is in are going there fordifferent starting to did have thatright because the difference was tellingyou what the right answer is okay andthat's what you push your center pointsso here I assume that I've been given atraining data which are described interms of features and the correct label1 of 0 and I will start with somevariable so now I just give up on Thetasand start thinking in terms of W eyes Istart having based on these linksweights of these leads okay and then Iwill bind up essentially if I usingthose weights of the current input I cancompute what comes out using thethresholding function and you comparethat to what should be coming out whichis the true value for that particularexample and you want to take thedifference square it because the momentwasted thinkingthe square there I'm like blah unlikethe RL example where we were doingonline learning here I don't have to doonline I can do offline learning whichmeans I've been given like 10,000examples so I pass all that I puttedexamples through this figure out whateach of them what is the error and sothe error from each of the examples willbe the true value for that example -what the output is from the passiveperceptron explain it and I sum thisover all the examples is the cumulativeerror over the training set right and Iwill then essentially try to minimizethat error and if you go through thesame sort of cross process that we needlast time the T is the two values sothere is no structure to it that that'sthe character and that's what you willdo what you come as the Oh however isthe weighted sum of the inputs forvirtue just example