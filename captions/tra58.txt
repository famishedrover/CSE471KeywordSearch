South g1g v g7 with these actions itstotal benefit net benefit would be thebenefit of all the goals it does - thecast of exaction City it sounded to mesleep there is no stochastic easilystochasticity more it is your Hansenit's just deterministic it's a muchharder problem than simple a-star searchit does in some years since you have youdon't even know how many co-hosts tofocus on so the search has to figure outimagine I'm actually looking for threegoals what's the best plan for fourgoals what's the best plan it's a ton ofall of this thing was the best by thattime is like a backfire but fire has tosee happen can people see this yesso are there determinist excursions thatuse on like varying values for the goalstay like for example a deterministicsearch will find a goal state and say ohthis will say it's worth two points butthen it might keep searching for a moreopposition find one that's worth onepoint or that exclusive in general sothe point is in this case obviouslypassing this class is class and billionunits like I've seen the exam is classthree units right and seeing that andseeing the movies lastly units having alife during the semester maybe plusfifteen units or something okay so giventhis out is pools of different valuesand they're not sleeping at all has acostremember that Korean guys every once ina while have some guy in South Koreadies and you think maybe they went toDemilitarized Zone and started you knowthrowing rackets no video games for $79third-straight the video give thevariance so they're getting lots of lotsof video game benefit what is thatthat's important when I died so they geta typical people will say another SouthKorean person has passed away mostlyteenagers typically so this is the thingso it is not deterministic in mind in mycase not at Korea s but in my so mypoint is I want you guys to understandthe last thing I want people to say isget respectability by dropping buzzwordsyou see what I'm saying what yourproblem is is a simple graph search butyou realize people in Google like MVPsso examine really thinking in terms ofdoing that party piece with one agent nostochastic city full of sorrow abilityif you are doing a hugely complex outthat way for a single problem you mightget the job but you're out there thatnever ends that's my pointso you want to understand how things areconnected when you want to say MDB andgenerally say MVP is almost like sayingyeah I'm thinking of using Turingmachine we use our computationalsteering machines what do you want tosay that out you how many of you are 325so you figured out that you don't haveto jump all the way to 20 machines rightaway there are simpler models and ifyour model basing is what you can dothat beat up by the simpler model youknow you should use that function okayso keep this in mind this is called netbenefit problemnaturally okay so far so gooddoctor back right tell me very quicklywhere does MVP model foulokay so deterministic was the stochasticwhich one is MVP stochastic it allowsfantastic instantaneous was a generatinginstantaneous or security how many forsaturated how many percent instantaneousknow what is a distant addition is lookslike old-fashioned stuff you should gofor the BT why is iterativewhat does generative mean it's fine forwhat do a single action it takes timewhat are you modeling it so what a starsearch using purity you are not relatedif you think it's a star surfacemodeling instantaneous actions so is MDPyou are not considering what ishappening that you are doing actionremember what I said I said are s yes -and you're taking a whole bunch ofstates cannot come between s and s - ÿðis going onthat's what generating leads the veryfact that is just before and just afterand that happens instantaneously meansthis instantaneous action one of thenice things for MVP is essentially it islike they say there is an app for itthere is MVP for it okay so if you aredesperately into using MVPs withduration then you use what is called SMDB's semi Markov semi markov decisionprocesses semi markov decision processesand that will become clear as to whythat semithat's what essentially it's not my MVP30 seconds after the boom box isquestionable if only I had returnedtoday yes no no no I just asked don'tcombine dimensions observable arepartially observable yes sir it's a keydistinction is between do you know whereyou will be versus do you know where youaredo you know if you will be you need amodel of the world then you go there youare you need your eyes MVP's are fullyobservable you don't understand thisyou're missing the pointit's easy because it's harder thanestimates just so everything no okayMVP's by themselves are fully observablewhich is why the policy basically sayslook at the state and do the action thatyou're supposed to do in that state howthe heck are you supposed to do that ifyou know what the state is you don'tknow what the state is you see what I'msaying and you also see why people whomight first start thinking about MVPscan fall into all sorts of holes andI've been doing this for a gazillionyears so it's easy to laugh but it's Icompletely understand that you areexpectationsMeitner will take some time to come intoconnection with reality around youthat's the reason we're going somewhereslower here okay so I said there's anapp for everything so if you aredesperate about partial observabilitythere are ladies for nippyif you nearly any one possibility thereis pundit bombed if these are harderthan MVPs because you only haven'tbelieved about what state you are in youhave some sort of an idea and then youshould convert the belief state intoactions we stopped state into actionsyes no it's just basically especiallythe observations cannot cooperate that'sa different storyokay static versus dynamic static waseternity now you are just ecstaticwasn't static if I push you out but yeahis that it because what you are thinkingthe what is he changing okay um well howwill you deal with the dynamic ingeneral to deal with that we can be anextra agent that would be Marco gamesit's not and in a minute okay so howabout goals you had a star that was fullof satisfaction there's one cool youhave to achieve a fully achieve ityou'll get points it's not it doesn'treally mattersee I keep very close but I didn't reachthe one step sorry oh so is it full ofwater satisfaction for a Star SearchMVPs far she'll notice that has nothingto do with deterministicwhat does not enough stochastic becauseI just told you in the previous slide aversion of deterministic search whichwill be partial satisfaction because youare wondering what is a this problem ispartial satisfaction you have to then hegoes you have deterministicbut they have cos you have too manyghosts you're trying to figure out yourbrief cost-benefit ratio you do thisevery day all of us have to respond tohumongous number of mates you know takepart in all sorts of Twitter and SMSconversations and I also show up for theclass and also have sleep etc you letsome things fall partial satisfactionokay that's your MVP and it's what theremembering this the many things westill have you know for example ifyou're an observer for it if you haveboth a bounty quiz if you want to go tojewellery you have w70 peas and so onokay and here is the maybe tree that andit is brings to the table is partialsatisfaction boughs and Status the citythat's itbecause marvelous the average is fullsatisfaction and it every stream thoseare the only two things six differingfrom a star search right remember andyou'd be surprised how many boos alsosay we're using empty please have noclue as to these distinctions I justknow what should be one out there okayla pompe it's before actually computingthe policies this is actually an examplein the textbook I want to give you youknow it's a moral intuitions about thefact that policies what is an optimalpolicy I want to tell you how to computeoptimal policy but I can show youqualities and you can you can see thatit makes sense okay in this example okaywhat happened to do here this isbasically the same example whereoriginally the reward functionessentially said for every state thataward was minus zeroI keep everything else the same I justmade with the reward for each state infact I could have each state they won'tbe state dependent but I'll assume thatevery state has the same before whichinstead of being the number minus zeropoint zero food could be some othernumber okay let's see what happenssuppose the reward but each state isless than this magic number minus onepoint six to eighty four minus one pointsix two eight four that means ifremembers rewards one like negativewatts or like pores and you still areyou are you still alive are you stillalive and previously they were reallylight box point minus 0.04 going to getwhich is plus one look at the reward butjust being alivelike this is what I did to the almond Ijust changed the reward structure suchthat living is so miserable what is theoptimal cost you want to end it as soonas possible again please this is one ofthese places where people start thinkingsuicidal ideation please don't okay Iwill send you a reason as to why youshould but what the agent is a thinkingof yourself as a bozo AI agent but abozo AI agent this would be the optimalpolicy if you follow the algorithm oncomputer tomorrow's I'll tell them thatI didn't give you yet it will give youthis optimal policy the observablechange so you want to understanddepression if you want to understand notnecessarily just a psychologist you knowbut understand what the pressure mightbe depression makes people think thatjust living is so highly negatively warthat even though they can see thequality rewards out there let me know weare not beyond the mountains they justwanted that's what will happen to thisagent okay then it's in between minus0.42 minus 0.08 okay that's almost likeI was not one except slight differenceit turns out that it will be kind oflike that and the other one is exactlywhere actually none of desire so thisone is minus 0.2 to 1 to r s less than 0okay and interesting differences thisone when you are here is trying to golikethen it is here synchronously make sensenothing to exams how many of you havewalked on Grand Canyon trains especiallysomething like again this is a standingposition class we don't know what thenext sentence will be the next sentencein this case happens to be that Canyontraced how do you have what on BrightAngel versus kebab dream and are afraidof heights you might be walking butthere would be some people like me hereis the canyon here is the Train therelike this why going down the canyon isless important than not dying right bygoing towards the canyon this way ismuch slower I will reach 3 days afteryou guys reach the end of one of thecanyon I would die according to mydivine retreat I'm like you werereportedly if I'm alive I the tons ofmoney comes from happiness tons of faithin terms of everything so I just want toreduce any chance of me a virtually tiedhere is the interesting thing if I tryto go this way we pass the city there isa point for chance to escape and thereis no chance that I wanna do this whichare I did thatmr. Xing this is really you change thatyou want victory you see how people herein fact I keep saying to all my studentssomehow who are sitting here and to manypeople that the older I get the thingthat I want to know about somebody whocomes into my office are talks to me iswhat's their reward nation honestly ashumans our capabilities are more or lessthe same I understand that somebasketball players have less stochasticcity including the ball into the hoopthan I dobut most of few verses are about thesame level okay got me NASA as fast as acheetah all of us are living in the sameworld and yet some of us are long salesand ready to end it up some of us likehiding as if there are drugs poetry theolder I get the more I want to know whatyour reward metric means because we allhave seen that factor it is whyeverything actually makes a differenceKaepernick is making a friend such atripod so most map most that the word inthe classroom wall and anymore thatwe're living in we all have similarcapabilities similar transition dynamicsthe big difference in the white matrixokayso that's the thing that whateverbusiness you do you know how I computedthis part to make sense of this becausethat the world is so small I mean theone is so slow or negative that it'sit's what there is a good chance ofgetting here you want to keep thatbecause that's the big plus the last onereward for every state is greater thanzero and I like to call this thenightmare of the priests and thepreachers in the border who always wantto tell you there is a heaven there is ahell you have to be careful on they stopand you don't want to go to checkoutbecause it will as well as hell upStates who wants to edit out did youhaving fun at home party by leaning sohere is the great optimal policy we'llget the policy is there or evacuate thenyou'll hear Buddha say but you're hereperson you're about to end it all withmartyrdom and to Danny about to end itwith infamy still don't end it it's not- 1 + 1living is where all the planets Ichanged the same agent with the sametransition model same word space tobehave very differently what just forchange evil about numbers so thisactually you asked the question if Isaid that the more you know the older Iget I want to know what your rewardmetric is so typically I have an agent Iknow the transition model like peoplehave the same transition model as meapproximately that's it I know theystate space I want to know what's theenvironment so that's like learning thereward matrix when you are ready tolearning you can learn that transitionmodel you can also learn the rewardfunction learning of anything in thecontext of MVPs is about reinforcementlearning in particularly after whatmatrix has part of a strange reasonwe've called IRA it was read forlearning makes no sense whatsoever butthat's what it means so I'm basically Igroup you a transition probabilities Iknow the state space I want to figureout what you every want Ricky keys sothat it makes sense of your behavior andthe connections to IRL are things likeother words like that are plannedrecognition what exactly is your planwhat are you trying to be a goalrecognitionI see you kind of something around withexactly are you trying to provethese are now connected ideas okay anyquestions on this okay couple morechanges to the basic model until now Ididn't say how long does the agent leavethe agent of actions how many actionsare they kept to prove how much timedoes it get to play if the can takestuff online it doesn't matter becauseanytime you get a chance to play a newgame it doesn't matter that least youcan beat some action but in the contextof offline which is what we're going todo you need to know how long it will belive right they are basically new finiteamount of time so in some sense we areat DPS we are ready boundaries but thereare degrees also then we can remaincapitalized and so the variations arefinite horizon the horizon is theattendance for today for that reasonokay finite horizon so you try tooptimize the policy then you know youdon't live far maybe in my case hundredand seventy five or so years okay andeverybody have some number that's thereby negative I so you can live infinitehorizon you can optimize that if youwill do forever and you can have avariation of indefinite horizon you knowthat you would not you gonna do for afinite amount of time but you don't knowexactly how much of that finite means soI kind of I know that the probabilitythat people live beyond hundredseventy-five seems to be zero so mostlybecause you to die between one and100 s 107 or something is digested 116 Ithink is over this person so I'm goingto that one record can I help you by youknow what the point being that that's aninfinite horizon here's the Rakosiquestion customer do you realize youroptimal policy depends on whether yourhorizon is finite person and infinite inparticular actually Churchill said thefollowing quote which I wish maybe Ishould go and showing that code is your20 and Armada level of your hotness withyour body your mother has already becomemindless say Churchill is telling you apolicy about how to have politicalpersuasions and he's saying the optimalpolicy depends on how long you have leftin essence the same thing happens whenyou go to move managers portfoliomanagers portfolio managers you try tosay ayewhat for - I have money and the firstquestion is how old are you and thesecond question is how can you get yourPIN in style because you tend to kind ofhave connections in the family and so soabout you die anyway 55 and you are 54enjoy the money manyou see what I'm saying it's trueactually the financial policiesfinancial policies are age dependent infact just as Churchill said acting HenryFord said then you are below 30 youshould only invest in yourself but meanstake out the money and invest inyourself you need me the best in termsof drinking by these bozos who wants tomake contact and stuff but so he'sbasically saying until 30 you justinvest all the money in yourself thenyou invest multiple studies again yourealize the finite horizon means optimalpolicy depends on time of left to anyokay suppose I have that stage I haveactions I have horizon age which goesone two three etcetera to gauge how manypolicies how many different policies canI have if I have horizon gauge the moviebasically enough said in progress beforebut you didn't ask me at that time whatis the horizon in fact they should be apolicy for you no funny fact thereshould be a policy this is the policythat say with 15 years left to go on adifferent policy when 14 years left togo a different policy then 13 yearsafter more different policy and for meacceptable so if 15 is the horizon thereare 15 such policies there for each timehorizon there are a power s potentialpolicies the next time horizon anotherpowerlessnext time what is it another powersso you realizing that it's a drag tolive I'm sorry you know I think thatit's back to having a finite tourism itwould be a power SH the power s times His the number of policies you have tosearch through to solve X finite horizonMDP problem if you want to do it thegroup person so far infrared horizon His equal to infinity so clearly thereare a power s times infinity number ofpolicies right how many people thinkthat for infinite horizon ah you willhave infinite number of policies did yousee where I am goingfinite pretty bad it keeps going finitewe can finally take the finite weakerwhat's what's what's what's worse at onemore line infinite number of policiesjust a power us this is the fun of beingin trouble yeah of course anywhere elseexponentially Sam still screwed manmakes an explanation and I made you feelgood about because that is much whatstuff to the world that can empower usthey can be a power s times H out therecan be a power infinity so infinitehorizon problems only have a power ssolutions does this make senseyes she does why because it's how howmany of you know in Hilbert's hotelproblem yes tell me what sort of rulesyeah there is no complication infertility order they have differentnumber of rooms in itand that bottle is full the guy talkslike this guy comes can importaccommodate it yes you'll ask everybodyto shift one there's an extra room hegets in it then it is a spoon he personit number of new people come maybe youknow for 71 students right can you dealwith it yeah it's everybody oh it's yourroom our room wha X go to 2 X as yourroom then you have half of the roomsempty you put the new infinity of thepeople in the half of the rules this iscalculus this is telling you that yourintuitions about finite number of snowfor four infinities and the mostimportant thing here it turns out isthis your infinite horizon that eachever going to live for infinite amountof time then let's say you have livedfor 10 million years how many layershave left how many days are leftinfinitely so good for one year how manyyears are left infinitely so the policyshould not care what how long you haveto live make sense completely make senseokay so for finite dollars and it's ashin front of a zone it's a powerless comeon promises right and so the interestingthing is the textbook actually directlygoes to infinite horizon problem somesalsa in this class we will actuallysolve the finite other problems that tencows are a finite or lesser valueiteration and they just say when Hbecomes infinity that means infinitehorizon and it's much easier tounderstand it's like everything is likeyou know going inside caves on one handwe thought it would be easier thaninfinity and I said no finite have manymore policies than infinity then youthought okay so we'll probably be in atotally closed with a void finite I'mtelling you no actually solving thefinite horizon problem is easier tounderstand there's no magicunderstand an infinite horizon problemhas just a simple combination of andanother property maximum that's what wewill do so because of each actuallyafter this class today I will send you asmall video our for me walking youthrough a finite hours an MDP valueiteration listen to that and then wewill again talk about it next class andthen we actually doing networks okayindefinite we won't talk about very muchokay but another thing actually so soMVPs if you want to define it in thenorm of computer science perspectivethen you have some set of states someset of actions some transitionprobability function PSAs - is propertythat you get - as - given that you're instate s and you doing actually guessthese are definitions okay and thehorizon age is the number of actions youget to do okay and then there is areward for geladas in fact as I saidthat in more general terms it's like ourSAS - just like TSSand the textbook actually just lefttakes RS and also takes