and then you can either follow thegreedy policy or you can do with epsilonprobability do something random in thecase of ADP computing the greedy policyat that point would have involvedconverting the value into PI was using Tok in q-learning as long as you havefuse you wrote your greedy policy rightnow whatever state you are in the illwith the highest Q is the best actionthat's it it's in front of you soexploration becomes even simpler thanwith probability 1 minus Epsilon yourepeat the action with the highest Qvalue in the state with probabilityEpsilon you pick any of the other edgeany other actions not just any of theother actions any of their actionsrandomly because the other random thingyou would consider all actions andprocess a crime so this reaction canalso be picked up in the random side isyour exam but this is children withexplanation truly and in case you arewondering the alphago and in fact thefirst whatever those Atari games thingsuse dqm remember the email servicecamera or the DQ n the queue correspondsto Q learning and the D corresponds toactually representing the Q function asa deep neural network instead of Qfunction as a table which is what we aredoingin fact boiling from tables to functionsfor the Q values and values that supplyis the next big topic we'll be doingthat's essentially generalization okayso there are two kinds of learning oneis Veronica waters future the happinessgeneralized emotional and both one isthat adaptive learning the other iscalled the enforcement run okayI'm actually going to skip over thesefew things that I wanted to sleep underseveral some of these types keep thisthing mighty this is a beautiful cycleso you have value on policy which if youget experience got some experience usingmodel free learning directly to whereyour policy we can go from experience tomodel which is a transition functionthen use bellman updates and this partis called landing in essence using thatone updatesyou know what are these transitionfunction using government updates tocompute the value given the model iscalled the landing so you can either doplanning and get this article godirectly here planning is done in yourhead which is why I said having a modelmeans you have the ability to plan yourtrip to Beijing without just doing theNike thing and saying and stand on theroad and figure out there as to swimfrom point A to point B you don't plantyou just jump in and do it because youmiss the model okay so that's a verybeautiful picture to keep in mind so abunch of things that I want to end ondata quickly before we end today one isthat even though funeral issues that theagent has to act in the real world it'ssomething that for the evening td-30 forexamI'm Olivia what will happen what whatanytime even if you have a mass we canalways act in a boring thing okayit's costly and you can die I just hopeI hope that I'm not be so scared ofacting but you just in the class andnever move ever you know because I'mbasically every time I'm saying what isacting in the world they can make youthat so you also can get you knowadvices so yes they can but it willalways work this is true reinforcementlearning the version of reinforcementI'm armed with its simulator it worksthe agent using the simulator instead ofthe rear void like using the flightsimulator etc are using the gamesimulator etcetera the quantity ofsimulator since you don't die you saywhy would be gained and it's still notmatter simulation it's like an externalsimulator but a quid cheaper can avoidthe not a participant world we're in thereal what if you die you don't come backto the similarity of that you cancontinue okay be faster and cheaper thanthe otherhowever someone has to have a built thesecured creditor for you nobody has togive you the art is there mass is thereyou want to go either what mass you canjust do all of us is whatever you aredoing it but if you want a masssimulator somebody has to be did firstby a third thing which we deal withlisting only because of the depth erawhere everything minds are beinguploaded into the web is instead of youlearning from one human experiences youcan learn from other people'sexperiences I kind of you be humans dothis except we tend to take the oldexperiences write books about them andthen wethose books so the books are kind oftell me the important parts of theexperience if you don't have that youcan still say I just can't everypossible set of transitions sequence oftransitions some other agents have donein their lives and then I will justbasically use them to figure out if Idid this what would happen if I do thisand use their experience for doing myKinney you see what I'm sayingthis actually has become possible onlybecause a web where everything ishappening without the unlined so forexample I forego that places of gamesplayed by millions of people that wasavailable to it and could just use themso it could give their lives just bykind of checking through them normal youmust really go crazy doing that but forcomputers and store that's possiblethe other thing that tells you why I'mwearing the basket for a t-shirt todayfor professional games especially likeNBA basketball because my son works as adata scientist there so I know somethingabout it tracking data that's capturedso for example in the NBA professionalbasketball is a huge amounts of camerathat's actually record everything that'sgoing on on that clinical space they arevery high quality tracking data and youcan use this data to do activityrecognition and then you can actuallyfigure out what happened to other peopledoing various things and then run RL onthis tracking data this is a hugeopportunity I am sold for doinganalytics before this M in the past thisstuff was there but people can keep onI showed you mine coming I'm never doingvideo sometimes when you have tons andtons of traces so learn some otherpeople stand experiences is useful letme just show a case that these lightsexist I know that you cannot do thiswithout RL in some areas like DDT butcitations picture I show you or you hedoesn't our weekly special time becauseit approximate dynamic programming andthis light tells you the difference theidea is there may be kinases did youhave the model okay DNR available butyou don't want to use them if you haveTMR you should just do em de right boxequation valuation our mind no inferenceyou may not want to say you might sayDNR up there it's like the textbook isway for this class that actually soplease tell us some review materialwhich is like you kind of sample thetextbook and tell us some little thingsthat we should study for the exam sothat when somehow win the exam that isbasically approximate preparation forexample approximately dynamic programwhere you stop using even so you havethe model you don't want to use themodel instead you act as if the modelwill be a simulator of this world inwhich you will do other it's completelycrazy but that's the kind of thing youguys do especially when I say there isan open book exampeople don't prepare for the exam at allthey just bring all their notebooks Isaid what sure during the exam I canvery quicklynot if I ever say open book exam I can'teven be sure that the time taken to flipthe pages the cumulative time thing toflip the pages would mean longer thanthe time of the exam so you shouldactually have studied before but this iskind of an approximately even though youhave that model we didn't want to musicbecause it looks too costly the nightbefore you wanted to go to a movie sothat's basically what's calledapproximate dynamic programming and sothis Abba completely removes thedistinction between learning because youdidn't have the model versus having themodel and just doing inference here Ihave the mana but I still want to doinference I want to learn crazy stuffbut that's what I don't hear is peoplepicked up and maybe backing up this lastquantity we want sparsity and then whatshaping the thing that makes enforcementis very hard typically is for largenumbers of partitions there are norewards and in the end you will say youneed abuse for example in chess game allthe intermediate moves have no value atthe end either you will not lose thecolor difference learning will be veryslow to converge in those kinds ofscenarios so normally when people sayreinforce petanque doesn't work too wellthey mean real word doesn't have enoughrewards it's too sparse anyone and is itonly comes on at the end now if you aredesigning the word where you knowenforcement learning agents are going tobe working such as yourself you want tokind of make rewards so that they didn'thave their enthusiasm up until the endof the semester so you can reward shapeby saying there are overcurrent thereare victim point if there is other coinsthere are other points but finally theonly thing that mattersfor the course is the course grief andthe to reward is at the end of thecourse you'll say drop what your gradeis in fact the true reward is not eventhat in fact the most of these rewardsthat I make up might make the agentgoing on directions but they could becompletely spurious words they may nothave any combination in the true valueso for example I think homeworksmidterms bachelor's degrees and weplease these are these are our pseudorewards the only reward is getting overChrist maybe so the last thing I wantednaturally that is joked that June is abunch of scholars were discussingbenders boxpark when does in does itstart at the moment of conception whenthe baby comes out because of cloud thisis the 54 pro-choice versus pro-life andthe Judaic Salah are saith you know in2000 we don't have this problem becausewe don't consider the point s to be ahuman being until it gets its PhDwe've enacted